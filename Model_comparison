# -*- coding: utf-8 -*-
"""Model_comparison.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14EtnMOmJ4aLWKzrnhewQVV9yvVwgU5Hc
"""

import numpy as np
import pandas as pd


from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()
X = data.data
y = data.target

pd.DataFrame(X).head()

X.shape

# test_training_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)

#feature scaling
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# empty list to store the result of models
models_results = []

#KNN
#train the model
knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)
#make predictions
y_pred_knn = knn_model.predict(X_test)

knn_acc = accuracy_score(y_test, y_pred_knn)
knn_prec = precision_score(y_test, y_pred_knn)
knn_rec = recall_score(y_test, y_pred_knn)
knn_f1 = f1_score(y_test, y_pred_knn)
knn_cm = confusion_matrix(y_test, y_pred_knn)

print(f"Accuracy: {knn_acc:.4f}")
print(f"Precision: {knn_prec:.4f}")
print(f"Recall: {knn_rec:.4f}")
print(f"F1 Score: {knn_f1:.4f}")
print("Confusion Matrix:\n", knn_cm)

models_results.append({
    "Model": "KNN",
    "Accuracy": knn_acc,
    "Precision": knn_prec,
    "Recall": knn_rec,
    "F1 Score": knn_f1,
    "Confusion Matrix": knn_cm
})

#Logistic Regression
logistic_model = LogisticRegression()
logistic_model.fit(X_train, y_train)
y_pred_logistic = logistic_model.predict(X_test)

logistic_acc = accuracy_score(y_test, y_pred_logistic)
logistic_prec = precision_score(y_test, y_pred_logistic)
logistic_rec = recall_score(y_test, y_pred_logistic)
logistic_f1 = f1_score(y_test, y_pred_logistic)
logistic_cm = confusion_matrix(y_test, y_pred_logistic)

print("Accuracy: ",logistic_acc)
print(f"Accuracy: {logistic_acc:.4f}")
print(f"Precision: {logistic_prec:.4f}")
print(f"Recall: {logistic_rec:.4f}")
print(f"F1 Score: {logistic_f1:.4f}")
print("Confusion Matrix:\n",logistic_cm)

models_results.append({
    "Model": "Logistic Regression",
    "Accuracy": logistic_acc,
    "Precision": logistic_prec,
    "Recall": logistic_rec,
    "F1 Score": logistic_f1,
    "Confusion Matrix": logistic_cm
})

#L1 Regularization
l1_model = LogisticRegression(
    penalty='l1',
    solver='liblinear',
    C=1.0
)
l1_model.fit(X_train, y_train)
y_pred_l1 = l1_model.predict(X_test)

l1_acc = accuracy_score(y_test, y_pred_l1)
l1_prec = precision_score(y_test, y_pred_l1)
l1_rec = recall_score(y_test, y_pred_l1)
l1_f1 = f1_score(y_test, y_pred_l1)
l1_cm = confusion_matrix(y_test, y_pred_l1)

print(f"Accuracy: {l1_acc:.4f}")
print(f"Precision: {l1_prec:.4f}")
print(f"Recall: {l1_rec:.4f}")
print(f"F1 Score: {l1_f1:.4f}")
print("Confusion Matrix:\n",l1_cm)

models_results.append({
    "Model": "L1 Regularization",
    "Accuracy": l1_acc,
    "Precision": l1_prec,
    "Recall": l1_rec,
    "F1 Score": l1_f1,
    "Confusion Matrix": l1_cm
})

# L2 Regularization
l2_model = LogisticRegression(
    penalty = 'l2',
    solver = 'lbfgs',
    C = 1.0
)
l2_model.fit(X_train, y_train)
y_pred_l2 = l2_model.predict(X_test)

l2_acc = accuracy_score(y_test, y_pred_l2)
l2_prec = precision_score(y_test, y_pred_l2)
l2_rec = recall_score(y_test, y_pred_l2)
l2_f1 = f1_score(y_test, y_pred_l2)
l2_cm = confusion_matrix(y_test, y_pred_l2)

print(f"Accuracy: {l2_acc:.4f}")
print(f"Precision: {l2_prec:.4f}")
print(f"Recall: {l2_rec:.4f}")
print(f"F1 Score: {l2_f1:.4f}")
print("Confusion Matrix:\n",l2_cm)

models_results.append({
    "Model": "L2 Regularization",
    "Accuracy": l2_acc,
    "Precision": l2_prec,
    "Recall": l2_rec,
    "F1 Score": l2_f1,
    "Confusion matrix": l2_cm
})

#Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
y_pred_linear = linear_model.predict(X_test)
y_pred_linear = (y_pred_linear > 0.5).astype(int)

linear_acc = accuracy_score(y_test, y_pred_linear)
linear_prec = precision_score(y_test, y_pred_linear)
linear_rec = recall_score(y_test, y_pred_linear)
linear_f1 = f1_score(y_test, y_pred_linear)
linear_cm = confusion_matrix(y_test, y_pred_linear)

print(f"Accuracy: {linear_acc:.4f}")
print(f"Precision: {linear_prec:.4f}")
print(f"Recall: {linear_rec:.4f}")
print(f"F1 Score: {linear_f1:.4f}")
print("Confusion Matrix:\n",linear_cm)

models_results.append({
    "Model": "Linear Regression",
    "Accuracy": linear_acc,
    "Precision": linear_prec,
    "Recall": linear_rec,
    "F1 Score": linear_f1,
    "Confusion Matrix": linear_cm
})

# Decision Tree
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

dt_acc = accuracy_score(y_test, y_pred_dt)
dt_prec = precision_score(y_test, y_pred_dt)
dt_rec = recall_score(y_test, y_pred_dt)
dt_f1 = f1_score(y_test, y_pred_dt)
dt_cm = confusion_matrix(y_test, y_pred_dt)

print(f"Accuracy: {dt_acc:.4f}")
print(f"Precision: {dt_prec:.4f}")
print(f"Recall: {dt_rec:.4f}")
print(f"F1 Score: {dt_f1:.4f}")
print("Confusion Matrix:\n",dt_cm)

models_results.append({
    "Model": "Decision Tree",
    "Accuracy": dt_acc,
    "Precision": dt_prec,
    "Recall": dt_rec,
    "F1 Score": dt_f1,
    "Confusion Matrix": dt_cm
})

# Bagging(Decision Tree Base)
bagging_model = BaggingClassifier(
    estimator=DecisionTreeClassifier(),n_estimators=100,random_state=42
    )
bagging_model.fit(X_train, y_train)
y_pred_bagging = bagging_model.predict(X_test)

bagging_acc = accuracy_score(y_test, y_pred_bagging)
bagging_prec = precision_score(y_test, y_pred_bagging)
bagging_rec = recall_score(y_test, y_pred_bagging)
bagging_f1 = f1_score(y_test, y_pred_bagging)
bagging_cm = confusion_matrix(y_test, y_pred_bagging)

print(f"Accuracy: {bagging_acc:.4f}")
print(f"Precision: {bagging_prec:.4f}")
print(f"Recall: {bagging_rec:.4f}")
print(f"F1 Score: {bagging_f1:.4f}")
print("Confusion Matrix:\n",bagging_cm)

models_results.append({
    "Model": "Bagging Classifier",
    "Accuracy": bagging_acc,
    "Precision": bagging_prec,
    "Recall": bagging_rec,
    "F1 Score": bagging_f1,
    "Confusion Matrix": bagging_cm
})

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

rf_acc = accuracy_score(y_test, y_pred_rf)
rf_prec = precision_score(y_test, y_pred_rf)
rf_rec = recall_score(y_test, y_pred_rf)
rf_f1 = f1_score(y_test, y_pred_rf)
rf_cm = confusion_matrix(y_test, y_pred_rf)

print(f"Accuracy: {rf_acc:.4f}")
print(f"Precision: {rf_prec:.4f}")
print(f"Recall: {rf_rec:.4f}")
print(f"F1  score: {rf_f1:.4f}")
print("Confusion matrix:\n",rf_cm)

models_results.append({
    "Model": "Random Forest",
    "Accuracy": rf_acc,
    "Precision": rf_prec,
    "Recall": rf_rec,
    "F1 Score": rf_f1,
    "Confusion Matrix": rf_cm
})

# Support Vector Machine
svm_model_lnr = SVC(kernel='linear', C=100)
svm_model_lnr.fit(X_train, y_train)
y_pred_svm_lnr = svm_model.predict(X_test)

svm_lnr_acc = accuracy_score(y_test, y_pred_svm_lnr)
svm_lnr_prec = precision_score(y_test, y_pred_svm_lnr)
svm_lnr_rec = recall_score(y_test, y_pred_svm_lnr)
svm_lnr_f1 = f1_score(y_test, y_pred_svm_lnr)
svm_lnr_cm = confusion_matrix(y_test, y_pred_svm_lnr)

print(f"Accuracy: {svm_lnr_acc:.4f}")
print(f"Precision: {svm_lnr_prec:.4f}")
print(f"Recall: {svm_lnr_rec:.4f}")
print(f"F1 Score: {svm_lnr_f1:.4f}")
print("Confusion Matrix:\n",svm_lnr_cm)

models_results.append({
    "Model": "SVM Linear",
    "Accuracy": svm_lnr_acc,
    "Precision": svm_lnr_prec,
    "Recall": svm_lnr_rec,
    "F1 Score": svm_lnr_f1,
    "Confusion Matrix": svm_lnr_cm
})

svm_model_rbf = SVC(kernel='rbf', C=100, gamma='scale')
svm_model_rbf.fit(X_train, y_train)
y_pred_svm_rbf = svm_model_rbf.predict(X_test)

svm_rbf_acc = accuracy_score(y_test, y_pred_svm_rbf)
svm_rbf_prec = precision_score(y_test, y_pred_svm_rbf)
svm_rbf_rec = recall_score(y_test, y_pred_svm_rbf)
svm_rbf_f1 = f1_score(y_test, y_pred_svm_rbf)
svm_rbf_cm = confusion_matrix(y_test, y_pred_svm_rbf)

print(f"Accuracy: {svm_rbf_acc:.4f}")
print(f"Precision: {svm_rbf_prec:.4f}")
print(f"Recall: {svm_rbf_rec:.4f}")
print(f"F1 Score: {svm_rbf_f1:.4f}")
print("Confusion Matrix:\n",svm_rbf_cm)

models_results.append({
    "Model": "SVM RBF",
    "Accuracy": svm_rbf_acc,
    "Precision": svm_rbf_prec,
    "Recall": svm_rbf_rec,
    "F1 Score": svm_rbf_f1,
    "Confusion matrix": svm_rbf_cm
})

#Linear Discriminant Analysis (LDA)
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda_model = LinearDiscriminantAnalysis()
lda_model.fit(X_train, y_train)
y_pred_lda = lda_model.predict(X_test)

lda_acc = accuracy_score(y_test, y_pred_lda)
lda_prec = precision_score(y_test, y_pred_lda)
lda_rec = recall_score(y_test, y_pred_lda)
lda_f1 = f1_score(y_test, y_pred_lda)
lda_cm = confusion_matrix(y_test, y_pred_lda)

print(f"Accuracy: {lda_acc:.4f}")
print(f"Precision: {lda_prec:.4f}")
print(f"Recall: {lda_rec:.4f}")
print(f"F1 Score: {lda_f1:.4f}")
print("Confusion Matrix:\n", lda_cm)

models_results.append({
    "Model": "LDA",
    "Accuracy": lda_acc,
    "Precision": lda_prec,
    "Recall": lda_rec,
    "F1 Score": lda_f1,
    "Confusion Matrix": lda_cm
})

# Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

nb_acc = accuracy_score(y_test, y_pred_nb)
nb_prec = precision_score(y_test, y_pred_nb)
nb_rec = recall_score(y_test, y_pred_nb)
nb_f1 = f1_score(y_test, y_pred_nb)
nb_cm = confusion_matrix(y_test, y_pred_nb)

print(f"Accuracy: {nb_acc:.4f}")
print(f"Precision: {nb_prec:.4f}")
print(f"Recall: {nb_rec:.4f}")
print(f"F1 Score: {nb_f1:.4f}")
print("Confusion Matrix:\n",nb_cm)

models_results.append({
    "Model": "Naive Bayes",
    "Accuracy": nb_acc,
    "Precision": nb_prec,
    "Recall": nb_rec,
    "F1 Score": nb_f1,
    "Confusion Matrix": nb_cm
})

#Comparison Table for all models
final_table = pd.DataFrame(models_results)
final_table
